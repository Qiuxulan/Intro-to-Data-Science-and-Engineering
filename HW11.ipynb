{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "互联网中充斥着大量钓鱼欺诈类网站。这类非法网站通常试图掩人耳目、充当正规网站，而实际上却是在窃取用户的身份、密码、交易等重要信息 机器学习在信息安全领域中的一个重要应用就是用来识别这些钓鱼网站。\n",
    "\n",
    "fraudulent.csv在data文件夹中。\n",
    "\n",
    "fraudulent.csv文件中含有10,086条数据，每条数据含有18个特征以及1个标签。各个特征的含义如下：\n",
    "contain_IP：网址中是否包涵ip，比如http://121.99.3.123/fake.html 包含ip。1表示包含，0表示不包含；\n",
    "is_long：网址字符是否过长。1表示网址过长，0表示网址不长；\n",
    "is_tinyurl：网址是否是短网址。比如https://bit.ly/2kXX6jV 就是短网址。1表示是短网址，0表示不是；\n",
    "contain_at：网址是否包含“@”符号。1表示包含，0表示不包含；\n",
    "contain_double_slash：网址是否包含“//”符号，该符号用来表示网址跳转。1表示包含，0表示不包含；\n",
    "contain_dash：网址是否包含“-”符号，该符号经常帮助用来伪装真网站，比如www.my-taobao.com 。 1表示包含，0表示不包含；\n",
    "contain_subdomain：网址是否包含子域名，比如www.ecnu.edu.cn 就包含edu和cn子域名。1表示包含，0表示不包含；\n",
    "is_SSL：网址是否是https安全链接。1表示包含，0表示不包含；\n",
    "with_long_history：网址所属的主域名存在的时间。1表示长久，0表示不长久；\n",
    "contain_icon：网址网页是否有小图标。1表示包含，0表示不包含；\n",
    "contain_ext_domain：该网页是否加载其他域名下的附件或者网页。1表示包含，0表示不包含；\n",
    "contain_email_to：该网页是否包含发送邮件的组件。1表示包含，0表示不包含；\n",
    "allow_right_click：该网页是否允许用户进行右击操作。1表示允许，0表示不允许；\n",
    "contain_pop_up_windowL：该网页是否包含弹窗。1表示包含，0表示不包含；\n",
    "contain_Iframe：该网页是否包含Iframe（嵌套网页）。1表示包含，0表示不包含；\n",
    "has_DNSRecord：网址是否有DNS记录。1表示有，0表示无；\n",
    "traffic：该网站的流量大小。1表示大，0表示小；\n",
    "google_rank：该网址在google搜索中的排名。1表示高于同类网站的平均排名，0表示低于同类网站的平均排名；\n",
    "\n",
    "y：表示网站是否是钓鱼欺诈网站，1表示是，0表示不是。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.原始数据中含有大量缺失值，请自行处理这些缺失值（可以剔除缺失值过多的列或者使用众数填充等方法）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10086 entries, 0 to 10085\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   contain_IP             9996 non-null   float64\n",
      " 1   is_long                9997 non-null   float64\n",
      " 2   is_tinyurl             9998 non-null   float64\n",
      " 3   contain_at             10004 non-null  float64\n",
      " 4   contain_double_slash   9970 non-null   float64\n",
      " 5   contain_dash           9992 non-null   float64\n",
      " 6   contain_subdomain      9989 non-null   float64\n",
      " 7   is_SSL                 9990 non-null   float64\n",
      " 8   with_long_history      7291 non-null   float64\n",
      " 9   contain_icon           8728 non-null   float64\n",
      " 10  contain_ext_domain     8559 non-null   float64\n",
      " 11  contain_email_to       8007 non-null   float64\n",
      " 12  allow_right_click      6679 non-null   float64\n",
      " 13  contain_pop_up_window  9807 non-null   float64\n",
      " 14  contain_Iframe         9427 non-null   float64\n",
      " 15  has_DNSRecord          8885 non-null   float64\n",
      " 16  traffic                8579 non-null   float64\n",
      " 17  google_rank            9422 non-null   float64\n",
      " 18  y                      10086 non-null  int64  \n",
      "dtypes: float64(18), int64(1)\n",
      "memory usage: 1.5 MB\n",
      "None\n",
      "   contain_IP  is_long  is_tinyurl  contain_at  contain_double_slash  \\\n",
      "0         1.0      1.0         1.0         1.0                   1.0   \n",
      "1         0.0      0.0         1.0         1.0                   1.0   \n",
      "2         0.0      0.0         1.0         1.0                   1.0   \n",
      "3         1.0      0.0         1.0         1.0                   1.0   \n",
      "4         1.0      0.0         1.0         1.0                   1.0   \n",
      "\n",
      "   contain_dash  contain_subdomain  is_SSL  with_long_history  contain_icon  \\\n",
      "0           0.0                1.0     0.0                0.0           1.0   \n",
      "1           0.0                0.0     0.0                0.0           NaN   \n",
      "2           0.0                1.0     1.0                NaN           NaN   \n",
      "3           0.0                0.0     0.0                1.0           1.0   \n",
      "4           0.0                0.0     1.0                NaN           1.0   \n",
      "\n",
      "   contain_ext_domain  contain_email_to  allow_right_click  \\\n",
      "0                 1.0               NaN                NaN   \n",
      "1                 1.0               1.0                1.0   \n",
      "2                 NaN               1.0                NaN   \n",
      "3                 0.0               1.0                1.0   \n",
      "4                 0.0               1.0                NaN   \n",
      "\n",
      "   contain_pop_up_window  contain_Iframe  has_DNSRecord  traffic  google_rank  \\\n",
      "0                    1.0             1.0            1.0      1.0          1.0   \n",
      "1                    0.0             1.0            NaN      1.0          0.0   \n",
      "2                    1.0             1.0            1.0      1.0          1.0   \n",
      "3                    1.0             1.0            1.0      1.0          1.0   \n",
      "4                    1.0             1.0            1.0      NaN          0.0   \n",
      "\n",
      "   y  \n",
      "0  0  \n",
      "1  1  \n",
      "2  0  \n",
      "3  1  \n",
      "4  0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据集\n",
    "data = pd.read_csv('D:\\\\Git-sub\\\\ItDSaE\\\\hw11_fraudulent.csv')\n",
    "\n",
    "# 查看数据的基本信息\n",
    "print(data.info())\n",
    "\n",
    "# 查看前几行数据\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contain_IP               0\n",
      "is_long                  0\n",
      "is_tinyurl               0\n",
      "contain_at               0\n",
      "contain_double_slash     0\n",
      "contain_dash             0\n",
      "contain_subdomain        0\n",
      "is_SSL                   0\n",
      "contain_icon             0\n",
      "contain_ext_domain       0\n",
      "contain_email_to         0\n",
      "contain_pop_up_window    0\n",
      "contain_Iframe           0\n",
      "has_DNSRecord            0\n",
      "traffic                  0\n",
      "google_rank              0\n",
      "y                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# 'with_long_history'和'allow_right_click'两列缺失值较多，直接删除\n",
    "data = data.drop(['with_long_history', 'allow_right_click'], axis=1)\n",
    "\n",
    "# 使用众数填充缺失值\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# 查看是否还有缺失值\n",
    "print(data_imputed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.将原始数据分为训练集、测试集（随机种子请设置为1）（若有需要可以将训练集进一步分为训练集和验证集）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: (8068, 16)\n",
      "测试集大小: (2018, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 提取特征和标签\n",
    "X = data_imputed.drop(columns=['y'])  # 特征\n",
    "y = data_imputed['y']  # 标签\n",
    "\n",
    "# 划分训练集和测试集，设置随机种子为1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 查看训练集和测试集的大小\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.现在请建立一个二分类模型，使用训练集训练模型，再使用测试集测试模型。\n",
    "分类模型可采用：k-近邻、决策树、逻辑回归、支持向量机等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1 Score: 0.8396\n"
     ]
    }
   ],
   "source": [
    "# k-近邻\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 创建并训练 KNN 模型\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# 计算 F1 值\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "print(f\"KNN F1 Score: {f1_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 Score: 0.8671\n"
     ]
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 创建并训练决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# 计算 F1 值\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 创建并训练逻辑回归模型\n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# 计算 F1 值\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression F1 Score: {f1_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 Score: 0.8610\n"
     ]
    }
   ],
   "source": [
    "# 支持向量机\n",
    "from sklearn.svm import SVC\n",
    "# 创建并训练支持向量机模型\n",
    "svm = SVC(random_state=1)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "\n",
    "# 计算 F1 值\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(f\"SVM F1 Score: {f1_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.评估指标为F1值\n",
    "可以与周围同学比较一下F1值的大小（越接近1越好），看看谁的数据预处理和分类模型更强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Scores for different models:\n",
      "KNN: 0.8396\n",
      "Decision Tree: 0.8671\n",
      "Logistic Regression: 0.8500\n",
      "SVM: 0.8610\n",
      "\n",
      "Best Model: Decision Tree with F1 Score: 0.8671\n"
     ]
    }
   ],
   "source": [
    "# 打印各个模型的 F1 分数\n",
    "f1_scores = {\n",
    "    \"KNN\": f1_knn,\n",
    "    \"Decision Tree\": f1_dt,\n",
    "    \"Logistic Regression\": f1_lr,\n",
    "    \"SVM\": f1_svm\n",
    "}\n",
    "\n",
    "# 输出 F1 分数\n",
    "print(\"\\nF1 Scores for different models:\")\n",
    "for model, score in f1_scores.items():\n",
    "    print(f\"{model}: {score:.4f}\")\n",
    "\n",
    "# 输出最佳模型\n",
    "best_model = max(f1_scores, key=f1_scores.get)\n",
    "print(f\"\\nBest Model: {best_model} with F1 Score: {f1_scores[best_model]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
